name: TorchServe
files:
- name: torchserve.yaml
  options:
  - template: init_config
    options:
    - template: init_config/openmetrics
    - template: init_config/http
      overrides:
        proxy.hidden: true
        skip_proxy.hidden: true
        timeout.hidden: true
  - template: instances
    multiple_instances_defined: true
    options:
      - name: OpenMetrics
        description: | 
          TorchServe OpenMetrics endpoint configuration
        options:
          - template: instances/openmetrics
            overrides:
              openmetrics_endpoint.required: false
              exclude_metrics_by_labels.description: |
                A mapping of labels to exclude metrics with matching label name and their corresponding metric values. 
                To match all values of a label, set it to `true`.
    
                Note: Label filtering happens before `rename_labels`.
    
                For example, the following configuration instructs the check to exclude all metrics with
                a label `worker` or a label `pid` with the value of either `23` or `42`.
    
                  exclude_metrics_by_labels:
                    worker: true
                    pid:
                    - '23'
                    - '42'
              cache_shared_labels.description: |
                When `share_labels` is set, it instructs the check to cache labels collected 
                from the first payload for improved performance.
            
                Set this to `false` to compute label sharing for every payload at the risk 
                of potentially increased memory usage.
      - name: inference
        description: TorchServe Inference API endpoint configuration
        options:

          - name: inference_api_url
            required: false
            description: The TorchServe Inference API url to connect to.
            value:
              example: "http://localhost:8080"
              type: string
          - template: instances/http
      - name: management
        description: TorchServe Management API endpoint configuration
        options:
          - name: management_api_url
            required: false
            description: The TorchServe Management API url to connect to.
            value:
              example: "http://localhost:8081"
              type: string
          - name: models
            description: |
              A list of models for which metrics should be collected.
            value:
              type: array
              items:
                type: string
          - name: models_discovery
            description: |
              A mapping of models autodiscovery patterns for which metrics should be collected.
            options:
              - name: limit
                description: |
                  Maximum number of models to be 'autodiscovered'.
                value:
                  type: integer
                  example: 10
              - name: include
                description: |
                  List of regular expressions for models that will be 'autodiscovered'.
                value:
                  type: array
                  items:
                    type: string
              - name: exclude
                description: |
                  List of regular expressions with the patterns of models that will not be 'autodiscovered'
                value:
                  type: array
                  items:
                    type: string
          - template: instances/http

